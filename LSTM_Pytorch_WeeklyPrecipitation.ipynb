{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8da86ec5",
   "metadata": {
    "id": "8da86ec5"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "import numpy as np\n",
    "!pip install pytorch \n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "xL6Y-IS3ksaQ",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 21310,
     "status": "ok",
     "timestamp": 1625027747675,
     "user": {
      "displayName": "DAVID RESTREPO",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgqxItBQRJ0dDzIdCZM0BMuA0KeTKTlKRNGMApY=s64",
      "userId": "09638303782015555303"
     },
     "user_tz": 300
    },
    "id": "xL6Y-IS3ksaQ",
    "outputId": "c35334cd-df0a-4305-e769-c9c26d90ec6b"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "#connect with drive\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "p7MwJk2JksoL",
   "metadata": {
    "id": "p7MwJk2JksoL"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "# Path to data:\n",
    "# David's path\n",
    "path = '/content/drive/MyDrive/Dengue_GIS_Visualization/DengueData/'\n",
    "# Dana's path\n",
    "#path='/content/drive/MyDrive/Dengue_GIS Visualization/Dengue_GIS_Visualization/DengueData/'\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lxt7_uXJKXrK",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 609
    },
    "executionInfo": {
     "elapsed": 1308,
     "status": "ok",
     "timestamp": 1625027748982,
     "user": {
      "displayName": "DAVID RESTREPO",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgqxItBQRJ0dDzIdCZM0BMuA0KeTKTlKRNGMApY=s64",
      "userId": "09638303782015555303"
     },
     "user_tz": 300
    },
    "id": "lxt7_uXJKXrK",
    "outputId": "2f250d2e-6c41-47f3-c48a-748a3f1dc249"
   },
   "outputs": [],
   "source": [
    "# Read Data\n",
    "merge_cases_temp_precip = pd.read_csv('Data/merge_cases_temperature_WeeklyPrecipitation_timeseries.csv')\n",
    "# Remove extra column\n",
    "merge_cases_temp_precip = merge_cases_temp_precip.drop('Unnamed: 0', 1)\n",
    "merge_cases_temp_precip.LastDayWeek = pd.to_datetime(merge_cases_temp_precip.LastDayWeek)\n",
    "merge_cases_temp_precip"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "JDVHbhn9zGhb",
   "metadata": {
    "id": "JDVHbhn9zGhb"
   },
   "source": [
    "# Time Series"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "zxNDtkPwhKJt",
   "metadata": {
    "id": "zxNDtkPwhKJt"
   },
   "source": [
    "## Data visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d55f16d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 497
    },
    "executionInfo": {
     "elapsed": 355,
     "status": "ok",
     "timestamp": 1625027749334,
     "user": {
      "displayName": "DAVID RESTREPO",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgqxItBQRJ0dDzIdCZM0BMuA0KeTKTlKRNGMApY=s64",
      "userId": "09638303782015555303"
     },
     "user_tz": 300
    },
    "id": "6d55f16d",
    "outputId": "8fe0d2b7-d732-4a29-e774-937e949d8bb4"
   },
   "outputs": [],
   "source": [
    "# Dengue cases in time\n",
    "def timeseries (x_axis, y_axis, x_label):\n",
    "    plt.figure(figsize = (12, 8))\n",
    "    plt.plot(x_axis, y_axis, color ='black')\n",
    "    plt.xlabel(x_label) \n",
    "    plt.ylabel('Dengue Cases')\n",
    "\n",
    "timeseries(merge_cases_temp_precip['LastDayWeek'], merge_cases_temp_precip['cases_medellin'], 'cases by Week')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3be7476a",
   "metadata": {
    "id": "3be7476a"
   },
   "source": [
    "## DataSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3934515",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 450
    },
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1625027749335,
     "user": {
      "displayName": "DAVID RESTREPO",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgqxItBQRJ0dDzIdCZM0BMuA0KeTKTlKRNGMApY=s64",
      "userId": "09638303782015555303"
     },
     "user_tz": 300
    },
    "id": "b3934515",
    "outputId": "cca4ec44-a74a-4ce8-eb4c-491206346213"
   },
   "outputs": [],
   "source": [
    "dataset = merge_cases_temp_precip[['temperature_medellin','percipitation_medellin','cases_medellin']]\n",
    "dataset.index = merge_cases_temp_precip.LastDayWeek\n",
    "dataset  #DF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "JeddvRFhkTnY",
   "metadata": {
    "id": "JeddvRFhkTnY"
   },
   "source": [
    "# Prepare data to supervised learning time series"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "LFsBjJYWhZaQ",
   "metadata": {
    "id": "LFsBjJYWhZaQ"
   },
   "source": [
    "we will use:\n",
    "* data: is the dataframe in our case (Dengue Cases, Precipitation and Temperature)\n",
    "* n_in: is the number of lag weeks in the past (length of window)\n",
    "\n",
    "The heart of this \"series_to_supervised\" function is the <a href=\"https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.shift.html\">shift</a> fuction of pandas\n",
    "\n",
    "This function gets as input the number of periods(in this case the number of weeks represented as rows up or down in the dataframe) to move the columns of a dataframe.\n",
    "E.g. \n",
    "* If we have merge_cases_temp_precip['cases_medellin'].shift(1) all the rows of column cases_medellin will move one row down\n",
    "* If we have merge_cases_temp_precip['cases_medellin'].shift(-1) all the rows of column cases_medellin will move one row up\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "BH5JesTNkW1V",
   "metadata": {
    "id": "BH5JesTNkW1V"
   },
   "outputs": [],
   "source": [
    "# prepare data for lstm\n",
    "from pandas import read_csv\n",
    "from pandas import DataFrame\n",
    "from pandas import concat\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# convert series to supervised learning\n",
    "def series_to_supervised(data, n_in=1, n_out=1, dropnan=True):\n",
    "\tn_vars = 1 if type(data) is list else data.shape[1]\n",
    "\tdf = DataFrame(data)\n",
    "\tcols, names = list(), list()\n",
    "\t# input sequence (t-n, ... t-1)\n",
    "\tfor i in range(n_in, 0, -1):\n",
    "\t\tcols.append(df.shift(i))\n",
    "\t\tnames += [('var%d(t-%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "\t# forecast sequence (t, t+1, ... t+n)\n",
    "\tfor i in range(0, n_out):\n",
    "\t\tcols.append(df.shift(-i))\n",
    "\t\tif i == 0:\n",
    "\t\t\tnames += [('var%d(t)' % (j+1)) for j in range(n_vars)]\n",
    "\t\telse:\n",
    "\t\t\tnames += [('var%d(t+%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "\t# put it all together\n",
    "\tagg = concat(cols, axis=1)\n",
    "\tagg.columns = names\n",
    "\t# drop rows with NaN values\n",
    "\tif dropnan:\n",
    "\t\tagg.dropna(inplace=True)\n",
    "\treturn agg\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4hM9aJnekTOF",
   "metadata": {
    "id": "4hM9aJnekTOF"
   },
   "source": [
    "### normalize features\n",
    "As we are working with a Neural Network the data values ​​must be normalized to help backpropagation algorithm\n",
    "So we will use the <a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.MinMaxScaler.html\">MinMaxScaler</a> from sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "gq1acAcggdew",
   "metadata": {
    "id": "gq1acAcggdew"
   },
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler(feature_range=(0, 1)) # Scaler between 0 and 1\n",
    "scaled = scaler.fit_transform(dataset) # As we can see data set has 3 Columns (This shape is also important for inverse scaler as we will see in future)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "HhBFNwjskQ0u",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 241
    },
    "executionInfo": {
     "elapsed": 236,
     "status": "ok",
     "timestamp": 1625027749565,
     "user": {
      "displayName": "DAVID RESTREPO",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgqxItBQRJ0dDzIdCZM0BMuA0KeTKTlKRNGMApY=s64",
      "userId": "09638303782015555303"
     },
     "user_tz": 300
    },
    "id": "HhBFNwjskQ0u",
    "outputId": "8732bf52-42b7-42ea-9b72-48aff0876925"
   },
   "outputs": [],
   "source": [
    "# length of window\n",
    "weeks = 10\n",
    "\n",
    "# frame as supervised learning\n",
    "data = series_to_supervised(scaled, n_in=weeks)\n",
    "DataFrame(data).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Uss0IPaQqnWB",
   "metadata": {
    "id": "Uss0IPaQqnWB"
   },
   "source": [
    "## Features Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eWFelunOgdml",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1625027749565,
     "user": {
      "displayName": "DAVID RESTREPO",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgqxItBQRJ0dDzIdCZM0BMuA0KeTKTlKRNGMApY=s64",
      "userId": "09638303782015555303"
     },
     "user_tz": 300
    },
    "id": "eWFelunOgdml",
    "outputId": "6c0bc37a-ca0c-499b-91cb-0e8affe88d49"
   },
   "outputs": [],
   "source": [
    "# We define the number of features as 3 (Temperature, Precipitation and Dengue Cases)\n",
    "n_features = 3\n",
    "# The features to train the model will be all except the values of the actual week \n",
    "# We can't use the temperature and precipitation in week t because whe need to resample a a 3D Array\n",
    "features_set = DataFrame(data.values[:,:-n_features])\n",
    "# Convert pandas data frame to np.array to reshape as 3D Array\n",
    "features_set = features_set.to_numpy()\n",
    "features_set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ojvAeBMPr3ol",
   "metadata": {
    "id": "ojvAeBMPr3ol"
   },
   "source": [
    "## Labels Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "q4jhxnI5gdqz",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1625027749565,
     "user": {
      "displayName": "DAVID RESTREPO",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgqxItBQRJ0dDzIdCZM0BMuA0KeTKTlKRNGMApY=s64",
      "userId": "09638303782015555303"
     },
     "user_tz": 300
    },
    "id": "q4jhxnI5gdqz",
    "outputId": "51826690-f319-4d9c-ab7b-bc84a5391782"
   },
   "outputs": [],
   "source": [
    "# We will use Dengue cases in last week \n",
    "labels_set = DataFrame(data.values[:,-1])\n",
    "# Convert pandas data frame to np.array\n",
    "labels_set = labels_set.to_numpy()\n",
    "labels_set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "RlwXfwaLsHza",
   "metadata": {
    "id": "RlwXfwaLsHza"
   },
   "source": [
    "## Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "-sb-9LCMgdwr",
   "metadata": {
    "id": "-sb-9LCMgdwr"
   },
   "outputs": [],
   "source": [
    "# We need a sequence so we can't split randomly\n",
    "# To divide into Train (90%) and test (10%) to do that we need to know the 90% of the total dataframe\n",
    "size = features_set.shape[0]\n",
    "split = int(size*(9/10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "_2LNWDMusZsl",
   "metadata": {
    "id": "_2LNWDMusZsl"
   },
   "source": [
    "### train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "FJan_zurgd1q",
   "metadata": {
    "id": "FJan_zurgd1q"
   },
   "outputs": [],
   "source": [
    "# We will train with 1st 90% of data and test with last 10%\n",
    "train_X = features_set[:split] ##90% train\n",
    "train_y = labels_set[:split]  ##90% train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "t17j8OtzemAG",
   "metadata": {
    "id": "t17j8OtzemAG"
   },
   "source": [
    "### test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "DS6rGhy5gd7B",
   "metadata": {
    "id": "DS6rGhy5gd7B"
   },
   "outputs": [],
   "source": [
    "test_X = features_set[split:] ##10% test\n",
    "test_y = labels_set[split:] ##10% test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "UExWrkq9Ib_J",
   "metadata": {
    "id": "UExWrkq9Ib_J"
   },
   "source": [
    "## Reshape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "G1xmvWGQgeDB",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1625027749566,
     "user": {
      "displayName": "DAVID RESTREPO",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgqxItBQRJ0dDzIdCZM0BMuA0KeTKTlKRNGMApY=s64",
      "userId": "09638303782015555303"
     },
     "user_tz": 300
    },
    "id": "G1xmvWGQgeDB",
    "outputId": "c3666bba-018f-4182-a51c-08593af61d1f"
   },
   "outputs": [],
   "source": [
    "# reshape input to be 3D [samples, timesteps, features]\n",
    "train_X = train_X.reshape((train_X.shape[0], weeks, n_features))\n",
    "test_X = test_X.reshape((test_X.shape[0], weeks, n_features))\n",
    "print(train_X.shape, train_y.shape, test_X.shape, test_y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e274707",
   "metadata": {},
   "source": [
    "### Transform ndarray to tensor pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b16a8c6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "train_X = torch.from_numpy(train_X)\n",
    "train_y = torch.from_numpy(train_y)\n",
    "test_X = torch.from_numpy(test_X)\n",
    "test_y = torch.from_numpy(test_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac223af3",
   "metadata": {
    "id": "ac223af3"
   },
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "h5ZtewNE5vXX",
   "metadata": {
    "id": "h5ZtewNE5vXX"
   },
   "source": [
    "### LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wPD_nuIfgeK9",
   "metadata": {
    "id": "wPD_nuIfgeK9"
   },
   "outputs": [],
   "source": [
    "\"\"\" TODO: Pytorch Model implementation\"\"\"\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import random\n",
    "random.seed(0)\n",
    "\n",
    "torch.manual_seed(0)\n",
    "\n",
    "\n",
    "# num_classes: weeks to predict (1)\n",
    "# num_layers: # of activations from past LSTM layers\n",
    "# input_size: num of features (n_features = 3)\n",
    "# hidden_size: # Neurons in hidden layer (50)\n",
    "# seq_length: length of window (weeks)\n",
    "\n",
    "class LSTM(nn.Module):\n",
    "\n",
    "    def __init__(self, num_classes, input_size, hidden_size, num_layers):\n",
    "        super(LSTM, self).__init__()\n",
    "        \n",
    "        self.num_classes = num_classes\n",
    "        self.num_layers = num_layers\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        \n",
    "        # Define LSTM layer with hidden_size neurons, input_size inputs and 1 ho and c0\n",
    "        self.lstm = nn.LSTM(input_size=input_size, hidden_size=hidden_size,\n",
    "                            num_layers=num_layers, batch_first=True)\n",
    "        # Define ouput linear layer takes hidden_size inputs, and num_classes outputs\n",
    "        self.fc = nn.Linear(hidden_size, num_classes)\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        h_0 = Variable(torch.zeros(\n",
    "            self.num_layers, x.size(0), self.hidden_size))\n",
    "        c_0 = Variable(torch.zeros(\n",
    "            self.num_layers, x.size(0), self.hidden_size))\n",
    "        # Propagate input through LSTM\n",
    "        ula, (h_out, _) = self.lstm(x, (h_0, c_0))\n",
    "        # print(f'last activation: {h_out}')\n",
    "        # print(f'output: {ula[:,-1,:]}') # Last Activation is output in last position\n",
    "        #print(h_out.shape)\n",
    "        h_out = h_out.view(-1, self.hidden_size)\n",
    "        out = self.fc(h_out)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "CRKoVYEqmcav",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6608,
     "status": "ok",
     "timestamp": 1625027756810,
     "user": {
      "displayName": "DAVID RESTREPO",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgqxItBQRJ0dDzIdCZM0BMuA0KeTKTlKRNGMApY=s64",
      "userId": "09638303782015555303"
     },
     "user_tz": 300
    },
    "id": "CRKoVYEqmcav",
    "outputId": "0540ea62-5239-46bd-a234-e7c5c7134343"
   },
   "outputs": [],
   "source": [
    "# Create instance of nn\n",
    "num_epochs = 2000\n",
    "learning_rate = 0.01\n",
    "\n",
    "input_size = n_features # Features\n",
    "hidden_size = 60 # LSTM layer neurons\n",
    "num_layers = 1 # Number of LSTM layers\n",
    "num_classes = 1 # Output Neurons\n",
    "\n",
    "# Instance\n",
    "lstm = LSTM(num_classes, input_size, hidden_size, num_layers)\n",
    "lstm = lstm.float()\n",
    "\n",
    "criterion = torch.nn.MSELoss()    # mean-squared error for regression\n",
    "optimizer = torch.optim.Adam(lstm.parameters(), lr=learning_rate)\n",
    "\n",
    "\n",
    "# fit network\n",
    "# Train the model\n",
    "for epoch in range(num_epochs):\n",
    "    outputs = lstm(train_X.float())\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    # obtain the loss function\n",
    "    loss = criterion(outputs, train_y.float())\n",
    "    \n",
    "    loss.backward()\n",
    "    \n",
    "    optimizer.step()\n",
    "    if epoch % 100 == 0:\n",
    "      print(\"Epoch: %d, loss: %1.5f\" % (epoch, loss.item()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "affd5824",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "C21mhuRullNL",
   "metadata": {
    "id": "C21mhuRullNL"
   },
   "outputs": [],
   "source": [
    "from math import sqrt\n",
    "from numpy import concatenate\n",
    "\n",
    "# make a prediction\n",
    "lstm.eval()\n",
    "train_predict = lstm(test_X.float())\n",
    "yhat = train_predict.detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "TtordubT422m",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1625027757308,
     "user": {
      "displayName": "DAVID RESTREPO",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgqxItBQRJ0dDzIdCZM0BMuA0KeTKTlKRNGMApY=s64",
      "userId": "09638303782015555303"
     },
     "user_tz": 300
    },
    "id": "TtordubT422m",
    "outputId": "2581c244-bce4-4bdd-bcdc-5358fa67ba69"
   },
   "outputs": [],
   "source": [
    "yhat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5Ozj32Jwq4VL",
   "metadata": {
    "id": "5Ozj32Jwq4VL"
   },
   "outputs": [],
   "source": [
    "# Convert test data to 2D \n",
    "test_X = test_X.reshape((test_X.shape[0], weeks*n_features))\n",
    "\n",
    "# invert scaling for forecast\n",
    "# As we said Scaler needs 3 columns so we can take those columns from test data and take again the predictions\n",
    "# Concatenate last 2 columns of test data with predicted data (yhat)\n",
    "inv_yhat = concatenate((test_X[:, -(n_features-1):], yhat), axis=1)\n",
    "# Inverse Scaler\n",
    "inv_yhat = scaler.inverse_transform(inv_yhat)\n",
    "# Take predicted data scaled to original Dengue cases\n",
    "inv_yhat = inv_yhat[:,-1]\n",
    "\n",
    "# invert scaling for actual\n",
    "# Same process than for predicted data (yhat)\n",
    "test_y = test_y.reshape((len(test_y), 1))\n",
    "inv_y = concatenate((test_X[:, -(n_features-1):], test_y), axis=1)\n",
    "inv_y = scaler.inverse_transform(inv_y)\n",
    "inv_y = inv_y[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "TdDRHwvNllQR",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1625027757308,
     "user": {
      "displayName": "DAVID RESTREPO",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgqxItBQRJ0dDzIdCZM0BMuA0KeTKTlKRNGMApY=s64",
      "userId": "09638303782015555303"
     },
     "user_tz": 300
    },
    "id": "TdDRHwvNllQR",
    "outputId": "2eb75315-8b91-40b5-a238-d8312b1823d7"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import  mean_absolute_error\n",
    "\n",
    "# calculate MAE\n",
    "mae = mean_absolute_error(inv_y, inv_yhat)\n",
    "print('Test MAE: %.3f' % mae)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "PJzx3p9psAqW",
   "metadata": {
    "id": "PJzx3p9psAqW"
   },
   "source": [
    "#### Plot predicted vs actual dengue cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nPOiCVoxsr-1",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 294
    },
    "executionInfo": {
     "elapsed": 510,
     "status": "ok",
     "timestamp": 1625027757815,
     "user": {
      "displayName": "DAVID RESTREPO",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgqxItBQRJ0dDzIdCZM0BMuA0KeTKTlKRNGMApY=s64",
      "userId": "09638303782015555303"
     },
     "user_tz": 300
    },
    "id": "nPOiCVoxsr-1",
    "outputId": "b42a1c50-d69b-4127-b3be-565a82bc972d"
   },
   "outputs": [],
   "source": [
    "data_predict = inv_yhat  ## predicted target  cases\n",
    "dataY_plot = inv_y  ##  real test-target cases\n",
    "\n",
    "data_predict = data_predict.reshape(len(data_predict), 1)\n",
    "dataY_plot = dataY_plot.reshape(len(dataY_plot), 1)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(dataY_plot, label = 'actual')\n",
    "plt.plot(data_predict, label = 'predicted')\n",
    "plt.legend(loc=\"upper left\")\n",
    "\n",
    "plt.suptitle('Time-Series Prediction')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "kMiD5Vp27n5W",
   "metadata": {
    "id": "kMiD5Vp27n5W"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9R-Zl5OgLo_h",
   "metadata": {
    "id": "9R-Zl5OgLo_h"
   },
   "source": [
    "<ol>\n",
    "  <li> <a href=\"https://towardsdatascience.com/predictive-analytics-time-series-forecasting-with-gru-and-bilstm-in-tensorflow-87588c852915\">Predictive Analytics: Time-Series Forecasting with GRU and BiLSTM in TensorFlow</a></li>\n",
    "  <li><a href=\"https://machinelearningmastery.com/multivariate-time-series-forecasting-lstms-keras/\">Multivariate Time Series Forecasting with LSTMs in Keras</a></li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "LA6ELSVJLpp0",
   "metadata": {
    "id": "LA6ELSVJLpp0"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7ded838",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f149814",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "019055d8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "GRU_TensorFlow_WeeklyPrecipitation.ipynb",
   "provenance": [
    {
     "file_id": "1EQz5vqDW0os0t6aKIInxWCiLPcWFpGkn",
     "timestamp": 1625027505883
    },
    {
     "file_id": "1yhwDjCPk8baHY-Odebdo8C1jIJVI5Uny",
     "timestamp": 1625026832717
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
